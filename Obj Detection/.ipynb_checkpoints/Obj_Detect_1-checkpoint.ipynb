{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14cf4ef4-0847-4602-b0c8-680fc1c75095",
   "metadata": {},
   "source": [
    "<h2>1. Import image and show using OpenCV </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36f258e-1eca-4dc9-b1ec-fede4fa39924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./Resources/lena.png\")\n",
    "cv2.imshow(\"Lena\", img)\n",
    "\n",
    "# waits indefinitely\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4e258b-13ca-43f1-8d26-795e76ad72cb",
   "metadata": {},
   "source": [
    "<h2>2. Import an existing video and show using OpenCV </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e136c9ab-80ba-4a00-bb8b-dca487bd106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# set the frame size, this is 720p\n",
    "frameWidth = 1280\n",
    "frameHeight = 720\n",
    "\n",
    "# take an existing video\n",
    "cap = cv2.VideoCapture(\"./Resources/testVideo.mp4\")\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    # if you need to resize the video:\n",
    "    #img = cv2.resize(img, (frameWidth, frameHeight))\n",
    "    \n",
    "    cv2.imshow(\"Video\", img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506414b-c50a-45a5-aa1a-ac0b65508625",
   "metadata": {},
   "source": [
    "<h2>3. Import webcam and show using OpenCV </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6eb0c95-c633-4d06-a6d6-2543875335cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# take an existing video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    # edge detection\n",
    "    imgEdge = cv2.Canny(img, 50, 100)\n",
    "    \n",
    "    cv2.imshow(\"Video\", imgEdge)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d4b38",
   "metadata": {},
   "source": [
    "<h2>4. Handy functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e1df6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "## required to make alterations to the image\n",
    "myKernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "## 1. Change image color using cvtColor\n",
    "img = cv2.imread(\"./Resources/heli\")\n",
    "img2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Lena\", img2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "## 2. Blur using GaussianBlur\n",
    "imgBlurr = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "cv2.imshow(\"Lena\", imgBlurr)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "## 3. Detect edges using canny\n",
    "imgCanny = cv2.Canny(imgBlurr, 100, 100)\n",
    "cv2.imshow(\"Lena\", imgCanny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "## 4. Dilate\n",
    "imgDilate = cv2.dilate(imgCanny, myKernel, iterations=1)\n",
    "cv2.imshow(\"Lena\", imgDilate)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "## 5. Erosion (inverse of dilation)\n",
    "imgErode = cv2.erode(imgDilate, myKernel, iterations=2)\n",
    "cv2.imshow(\"Lena\", imgErode)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc169f3b",
   "metadata": {},
   "source": [
    "<h2>5. Crop and resize image</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac6f48-40fb-4364-9f1b-bf5fa63cfe5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Unlike in mathemathics, positive X and Y axis point towards <b>North and East</b></br>\n",
    "In OpenCV, Positive X and Y axis are <b>South and East</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11702b02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1207, 1842, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"./Resources/heli.jpg\")\n",
    "\n",
    "## find the size of an image (height, width, number of channels):\n",
    "img_size = img.shape\n",
    "print(img_size)\n",
    "\n",
    "## resize an image\n",
    "width, height = 200, 400\n",
    "imgResized = cv2.resize(img, (width, height))\n",
    "\n",
    "## crop and image\n",
    "imgCropped = imgResized[200:300, 10:150]\n",
    "\n",
    "## enlarge resized image\n",
    "imgEnlarged = cv2.resize(imgCropped, (img.shape[1], img.shape[0]))\n",
    "\n",
    "## show the image\n",
    "cv2.imshow(\"Mi-17\", imgEnlarged)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694a8c3-2d07-4edc-9250-4d7530fc9b2d",
   "metadata": {},
   "source": [
    "<h2>6. Shapes and text</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5a64379-5ef6-41f4-9adb-c1173679e061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img.shape:  (512, 512, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "## create a blank image\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "print(\"img.shape: \", img.shape)\n",
    "\n",
    "## BGR -  turn the image to blue\n",
    "#img[:] = 255, 0, 0\n",
    "\n",
    "## Line - line(image, start, stop, color, thcikness)\n",
    "cv2.line(img, (0,0), (100, 100), (0, 255, 0), 2)\n",
    "\n",
    "## Rectangle - cv2.rectangle(image, start, end, color, thickness OR cv.FILLED)\n",
    "cv2.rectangle(img, (350, 100), (450, 200), (0, 0, 255), 2)\n",
    "\n",
    "## Circle - cv.circle(image, start, radius, color thickness)\n",
    "cv2.circle(img, (350, 400), 50, (0, 0, 255), 2)\n",
    "\n",
    "## Text - cv2.putText(image, text, start, font, fontScale, color, thicknessNone, lineTypesNone, bottomLeftOriginsNone)\n",
    "cv2.putText(img, \"This is a text.\", (75, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 150, 0), 1)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a2a4a1-2218-4309-8eae-e3e8e680f8ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>7. Stacking images</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d68f108-e2c0-489e-a07e-84cf7186034b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path = \"./Resources/lena.png\"\n",
    "\n",
    "img_1 = cv2.imread(path)\n",
    "img_2 = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "img_3 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## resize images\n",
    "img_1 = cv2.resize(img_1, (0, 0), None, 0.5, 0.5)\n",
    "img_2 = cv2.resize(img_2, (0, 0), None, 0.5, 0.5)\n",
    "img_3 = cv2.resize(img_3, (0, 0), None, 0.5, 0.5)\n",
    "\n",
    "## make sure the channels are the same (3)\n",
    "img_3 = cv2.cvtColor(img_3, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "## horizontally and vertically\n",
    "horizon = np.hstack((img_1, img_2, img_3))\n",
    "vertical = np.vstack((horizon, horizon))\n",
    "\n",
    "cv2.imshow(\"Horizontal\", horizon)\n",
    "cv2.imshow(\"Vertical\", vertical)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3126943-7549-4ab3-9915-d12a3681cbdf",
   "metadata": {},
   "source": [
    "<h3>7.1. The method above is fine but not very efficient, we can use a function instead: </h3>\n",
    "<h3>Source: https://www.computervision.zone/courses/learn-opencv-in-3-hours/</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc654186-6101-48cb-bb7c-00ce13478cc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a6dae5-9ca4-4c4a-8b08-a81b4d7d2a9f",
   "metadata": {},
   "source": [
    "<h3>7.2. Image implementation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12f8bf94-78a3-4410-b4a2-ba53c865e08a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "## required to make alterations to the image\n",
    "myKernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "img = cv2.imread(\"./Resources/lena.png\")\n",
    "img2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgBlurr = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "imgCanny = cv2.Canny(imgBlurr, 100, 100)\n",
    "imgDilate = cv2.dilate(imgCanny, myKernel, iterations=1)\n",
    "imgErode = cv2.erode(imgDilate, myKernel, iterations=2)\n",
    "\n",
    "## create a blank image as placeholder\n",
    "blankImg = np.zeros((img.shape[1], img.shape[0]), np.uint8)\n",
    "\n",
    "stackedImages = stackImages(0.8, ([img, img2, imgBlurr], [imgCanny, imgDilate, blankImg]))\n",
    "\n",
    "cv2.imshow(\"Stacked Images\", stackedImages)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a74f66-16d4-41a8-b32d-03150408e497",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>7.3. Webcam implementation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28dbf7c2-9c67-452e-ab69-8ed66d389cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# take an existing video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "## required to make alterations to the image\n",
    "myKernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    success, img = cap.read()\n",
    "    img2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    imgBlurr = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "    imgCanny = cv2.Canny(imgBlurr, 80, 80)\n",
    "    imgDilate = cv2.dilate(imgCanny, myKernel, iterations=1)\n",
    "    imgErode = cv2.erode(imgDilate, myKernel, iterations=2)\n",
    "\n",
    "    \n",
    "    blankImg = np.zeros((img.shape[1], img.shape[0]), np.uint8)\n",
    "    \n",
    "    \n",
    "    stackedImages = stackImages(0.5, ([img, img2, imgBlurr], \n",
    "                                      [imgCanny, imgDilate, blankImg]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Video pipeline ('q' to quit)\", stackedImages)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd5b67b-3e5b-4bef-b4ca-e32365bff2be",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>8. Angled image to bird view</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3df69-00fb-45c2-beb3-990a11e95cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "## load and resize image\n",
    "img = cv2.imread(\"./Resources/cards.jpg\")\n",
    "img = cv2.resize(img, (img.shape[1], img.shape[0]))\n",
    "\n",
    "## first we need to know the coord of all 4 points of the card\n",
    "pts1 = np.float32([[962, 494], [1157, 680], [671, 732], [867, 929]])\n",
    "\n",
    "## print the points on the image\n",
    "for coord in range(0,4):\n",
    "    cv2.circle(img, (int(pts1[coord][0]), int(pts1[coord][1])), 2, (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "## \n",
    "width, height = 250, 350\n",
    "pts2 = np.float32([[0,0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "imageOutput = cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "\n",
    "cv2.imshow(\"Cards\", img)\n",
    "cv2.imshow(\"Card\", imageOutput)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94750d1-cec1-44b4-8704-97bb68458823",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cards\n",
    "Top Left: 962, 494\n",
    "Top right: 1157, 680\n",
    "Bottom left: 671, 732\n",
    "Bottom Right: 867, 929\n",
    "\n",
    "## Micra plate\n",
    "Top Left: 706, 935\n",
    "Top right: 790, 909\n",
    "Bottom left: 706, 970\n",
    "Bottom Right: 791, 942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584cc4b9-c274-4235-90e3-9913afe5741f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "## load and resize image\n",
    "img = cv2.imread(\"./Resources/micra.png\")\n",
    "img = cv2.resize(img, (img.shape[1], img.shape[0]))\n",
    "\n",
    "## first we need to know the coord of all 4 points of the card\n",
    "pts1 = np.float32([[706, 935], [790, 909], [706, 970], [791, 942]])\n",
    "\n",
    "## print the points on the image\n",
    "for coord in range(0,4):\n",
    "    cv2.circle(img, (int(pts1[coord][0]), int(pts1[coord][1])), 2, (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "## \n",
    "width, height = 800, 300\n",
    "pts2 = np.float32([[0,0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "imageOutput = cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "\n",
    "cv2.imshow(\"Micra\", img)\n",
    "cv2.imshow(\"Micra Plate\", imageOutput)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd8ef4-f843-4daa-a430-cd7ab9426bd7",
   "metadata": {},
   "source": [
    "<h2>9. Click on an image to birdview</h2>\n",
    "<h4>Please select using the following order: Top left, Top right, Bottom left, Bottom right</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f069394-e796-424f-a5af-2518e5105c63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def mousePoint(event, x, y, flags, params):\n",
    "#    global counter\n",
    "#    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "#        circles[counter] = x, y\n",
    "#        counter = counter + 1\n",
    "#        print(circles)\n",
    "        \n",
    "def mousePoint(event, x, y, flags, params):\n",
    "        global global_index\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            if(global_index >= 0 and global_index < 4):\n",
    "                circles[global_index] = x,y\n",
    "                global_index += 1\n",
    "                #print(circles)\n",
    "            else:\n",
    "                print(\"Cannot select more than 4 points!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33fa81b5-e169-4059-a6e1-3793acf8fc8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "global_index = 0\n",
    "\n",
    "## create a matrix to store the clikcs\n",
    "circles = np.zeros((4, 2), np.int32)\n",
    "\n",
    "## load and resize image\n",
    "img = cv2.imread(\"./Resources/heli.jpg\")\n",
    "img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "\n",
    "while True:\n",
    "    if (global_index == 4):\n",
    "        ## first we need to know the coord of all 4 points of the card\n",
    "        pts1 = np.float32([circles[0], circles[1], circles[2], circles[3]])\n",
    "        \n",
    "        ## UPDATE: dynamically sets the size of the output image\n",
    "        width = 5 * (circles[1][0] - circles[0][0])\n",
    "        height = 5 * (circles[2][1] - circles[0][1])\n",
    "        \n",
    "        ## create points for the output image\n",
    "        pts2 = np.float32([[0,0], [width, 0], [0, height], [width, height]])\n",
    "\n",
    "        matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "        imageOutput = cv2.warpPerspective(img, matrix, (width, height))\n",
    "        \n",
    "        cv2.imshow(\"Card\", imageOutput)\n",
    "\n",
    "    ## print the points on the image\n",
    "    for coord in range(0,4):\n",
    "        cv2.circle(img, (int(circles[coord][0]), int(circles[coord][1])), 2, (0, 255, 0), cv2.FILLED)\n",
    "\n",
    "    # we set the callback on the main image\n",
    "    cv2.imshow(\"Cards\", img)\n",
    "    cv2.setMouseCallback(\"Cards\", mousePoint)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "250c6898-4d10-4aee-a2dc-559a1346cc4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[779   0]\n",
      " [  0   0]\n",
      " [  0   0]\n",
      " [  0   0]]\n",
      "-779 0\n"
     ]
    }
   ],
   "source": [
    "print(circles)\n",
    "width = circles[1][0] - circles[0][0]\n",
    "height = circles[2][1] - circles[0][1]\n",
    "print(width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a68b0-e6f6-4331-8717-8c76b9521c3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>10. Color Detection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55712644-da9c-4fab-a3bb-6250f89db1c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MAKE SURE TO RUN THE stackImages FUNCTION FIRST ##\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# take an existing video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "## create a window to control the HSV values\n",
    "cv2.namedWindow(\"HSV Controller\")\n",
    "cv2.resizeWindow(\"HSV Controller\", 640, 240)\n",
    "\n",
    "## add the trackbars to the window\n",
    "cv2.createTrackbar(\"Hue Min\", \"HSV Controller\", 0, 179, empty)\n",
    "cv2.createTrackbar(\"Hue Max\",\"HSV Controller\",19,179,empty)\n",
    "\n",
    "cv2.createTrackbar(\"Sat Min\",\"HSV Controller\",110,255,empty)\n",
    "cv2.createTrackbar(\"Sat Max\",\"HSV Controller\",240,255,empty)\n",
    "\n",
    "cv2.createTrackbar(\"Val Min\",\"HSV Controller\",153,255,empty)\n",
    "cv2.createTrackbar(\"Val Max\",\"HSV Controller\",255,255,empty)    \n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    ## convert BGR to HSV\n",
    "    imgHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) \n",
    "    \n",
    "    ## get the values of the trackbars\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\",\"HSV Controller\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\", \"HSV Controller\")\n",
    "    \n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\", \"HSV Controller\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\", \"HSV Controller\")\n",
    "    \n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\", \"HSV Controller\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\", \"HSV Controller\")\n",
    "    \n",
    "    lower = np.array([h_min,s_min,v_min])\n",
    "    upper = np.array([h_max,s_max,v_max])\n",
    "    \n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "    \n",
    "    imgResult = cv2.bitwise_and(img,img,mask=mask)\n",
    "    \n",
    "    ## show the image\n",
    "    #cv2.imshow(\"Original\", img)\n",
    "    #cv2.imshow(\"Video HSV\", imgHSV)\n",
    "    #cv2.imshow(\"Mask\", mask)\n",
    "    #cv2.imshow(\"Result\", imgResult)\n",
    "    \n",
    "    stackedImages = stackImages(0.8, ([img, imgHSV], [mask, imgResult]))\n",
    "    cv2.imshow(\"Stacked Images\", stackedImages)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281d20a-8508-4a86-a6c6-2a6e2150a294",
   "metadata": {},
   "source": [
    "<h2>11. Shape detection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7bc494-cf83-4b2c-8418-f2b9561daaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d310ee-9063-41b4-b01d-9a8fdc37f626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
