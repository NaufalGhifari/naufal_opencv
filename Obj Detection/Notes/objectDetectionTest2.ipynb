{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "########################################################################################################################################\n",
    "# function author: Murtaza \n",
    "# link: https://www.youtube.com/watch?v=Fchzk1lDt7Q&list=PLMoSUbG1Q_r_sc0x7ndCsqdIkL7dwrmNF&index=10\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "########################################################################################################################################\n",
    "# function author: Murtaza \n",
    "# link: https://www.youtube.com/watch?v=Fchzk1lDt7Q&list=PLMoSUbG1Q_r_sc0x7ndCsqdIkL7dwrmNF&index=10\n",
    "def getContours(img, imgContour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "\n",
    "    # We dont want contours that are below a certain area size\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 1000:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 255), 7)\n",
    "\n",
    "            peri = cv2.arcLength(cnt, True) # find perimeters\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * peri, True) # find how many points there are\n",
    "            # print(len(approx))\n",
    "\n",
    "            # for bounding box\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    "            cv2.rectangle(imgContour, (x, y), (x + w, y + h), (0, 255, 0), 5)\n",
    "\n",
    "########################################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# frame to display webcam\n",
    "frameWidth = 640\n",
    "frameHeight = 4800\n",
    "\n",
    "# capture video\n",
    "webcam = cv2.VideoCapture(0)\n",
    "\n",
    "\"\"\"\n",
    "The ID 3 corresponds to the property for setting the width of the video frame.\n",
    "The ID 4 corresponds to the property for setting the height of the video frame.\n",
    "\"\"\"\n",
    "webcam.set(3, frameWidth)\n",
    "webcam.set(4, frameHeight)\n",
    "\n",
    "def doNothing(a):\n",
    "    \"\"\"\n",
    "    This function gets called by the trackbar when updated, we dont want to do anything\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# create a trackbar window menu\n",
    "cv2.namedWindow(\"Parameters\")\n",
    "cv2.resizeWindow(\"Parameters\", 640, 240)\n",
    "\n",
    "# threshold values for canny edge detection\n",
    "cv2.createTrackbar(\"Canny upper\", \"Parameters\", 150, 255, doNothing)\n",
    "cv2.createTrackbar(\"Canny lower\", \"Parameters\", 150, 255, doNothing)\n",
    "\n",
    "while True:\n",
    "    success, img = webcam.read()\n",
    "    \n",
    "    # 1. apply gaussian blur - (7, 7) is kernel size\n",
    "    imgBlurred = cv2.GaussianBlur(img, (7, 7), 1)\n",
    "\n",
    "    # 2. turn image to greyscale\n",
    "    imgGrayed = cv2.cvtColor(imgBlurred, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 3. edge detection\n",
    "    threshold1Val = cv2.getTrackbarPos(\"Canny upper\", \"Parameters\")\n",
    "    threshold2Val = cv2.getTrackbarPos(\"Canny lower\", \"Parameters\")\n",
    "    imgEdgeDetect = cv2.Canny(imgGrayed, threshold1Val, threshold2Val)\n",
    "\n",
    "    # 4. dilate image\n",
    "    kernel = np.ones((5, 5))\n",
    "    imgDilated = cv2.dilate(imgEdgeDetect, kernel, iterations=1)\n",
    "\n",
    "    # 5. contouring\n",
    "    imgContour = img.copy()\n",
    "    getContours(imgDilated, imgContour)\n",
    "\n",
    "    # create an aggregate of images to display\n",
    "    displayed = stackImages(0.8, ([img, imgEdgeDetect, imgDilated],\n",
    "                            [imgContour, imgContour, imgContour]))\n",
    "\n",
    "\n",
    "    # display the images\n",
    "    cv2.imshow(\"Webcam stream\", displayed)\n",
    "\n",
    "    # press 'q' to close the webcam without crash\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing OpenCV package\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def doNothing(a):\n",
    "    \"\"\"\n",
    "    This function gets called by the trackbar when updated, we dont want to do anything\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def detectObjects(img, img_contour):\n",
    "    contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    # Applying object detction method\n",
    "    objects = object_cascade.detectMultiScale(img_contours, 1.1, 9)\n",
    "\n",
    "    # We dont want contours that are below a certain area size\n",
    "    for obj in objects:\n",
    "        area = cv2.contourArea(obj)\n",
    "        if area > 1000:\n",
    "            cv2.drawContours(imgContour, obj, -1, (255, 0, 255), 7)\n",
    "        \n",
    "        for (x, y, w, h) in objects:\n",
    "            cv2.rectangle(img_contours,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "\n",
    "# create a trackbar window menu\n",
    "cv2.namedWindow(\"Parameters\")\n",
    "cv2.resizeWindow(\"Parameters\", 640, 240)\n",
    "\n",
    "# threshold values for canny edge detection\n",
    "cv2.createTrackbar(\"Thresh 1\", \"Parameters\", 150, 255, doNothing)\n",
    "cv2.createTrackbar(\"Thresh 2\", \"Parameters\", 150, 255, doNothing)\n",
    "\n",
    "# Loading the required haar-cascade xml classifier file\n",
    "object_cascade = cv2.CascadeClassifier('./cascades/tank.xml')\n",
    "\n",
    "# Reading the image\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    \n",
    "    img_blur = cv2.GaussianBlur(img, (7, 7), 1)\n",
    "    img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    threshold1Val = cv2.getTrackbarPos(\"Thresh 1\", \"Parameters\")\n",
    "    threshold2Val = cv2.getTrackbarPos(\"Thresh 2\", \"Parameters\")\n",
    "    img_edge = cv2.Canny(img_blur, threshold1Val, threshold2Val)\n",
    "\n",
    "    kernel = np.ones((5, 5))\n",
    "    img_dilated = cv2.dilate(img_edge, kernel, iterations=1)\n",
    "\n",
    "    img_contour = img.copy()\n",
    "    getContours(img_dilated, img_contour)\n",
    "\n",
    "    img_contours = img.copy()\n",
    "    detectObjects(img_dilated, img_contours)\n",
    "\n",
    "    # display the images\n",
    "    cv2.imshow(\"Webcam stream\", img_contours)\n",
    "\n",
    "    # press 'q' to close the webcam without crash\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "# Pseudocode for training a Haarcascade model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Collect positive images with the object you want to detect\n",
    "Collect negative images without the object\n",
    "\n",
    "Create a text file 'positive.txt' with paths to positive images and object coordinates\n",
    "Create a text file 'negative.txt' with paths to negative images\n",
    "\n",
    "Generate positive samples:\n",
    "for each positive image in 'positive.txt':\n",
    "    apply variations to the image (rotation, scaling, noise)\n",
    "    save the modified image\n",
    "\n",
    "Create a vector file 'positives.vec' using modified positive images\n",
    "opencv_createsamples -info positive.txt -vec positives.vec -w width -h height\n",
    "\n",
    "Train the cascade:\n",
    "opencv_traincascade -data output_directory -vec positives.vec -bg negative.txt -numStages N\n",
    "\n",
    "Evaluate the classifier:\n",
    "for each test image:\n",
    "    use the trained cascade to detect objects\n",
    "    calculate precision, recall, and accuracy metrics\n",
    "\n",
    "Tune parameters and retrain:\n",
    "adjust cascade parameters (numStages, minHitRate, maxFalseAlarmRate)\n",
    "retrain the cascade using the updated parameters\n",
    "\n",
    "Use the trained cascade:\n",
    "load the trained cascade using cv2.CascadeClassifier\n",
    "use the cascade to detect objects in images or videos\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
